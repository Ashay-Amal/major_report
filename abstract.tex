\chapter*{Abstract}
\thispagestyle{plain}
\addcontentsline{toc}{chapter}{\numberline{}Abstract}

The project proposes a CycleGAN based Neural Style Transfer (NST) system for converting photographs into four distinct artistic styles of One Piece anime, Disney, Studio Ghibli, and paintings by Van Gogh. The system will utilize unpaired data sets with cycle-consistency constraints, which allows for the bidirectional mapping of human faces to animated characters and scenery to post-impressionist style works of art.\\

Utilization of the generator-discriminator (GAN-D) model involves utilizing both a generator and discriminator to create realistic artwork through adversarial loss, preserve content using Cycle-consistency loss, use identity loss for colour preservation, and incorporate VGG-19 perceptual loss. OpenCV's custom frame extraction method retrieves animated datasets from video sources, while Van Gogh datasets are constructed using landscapes and paintings retrieved from Kaggle.\\

Utilizing PyTorch 2.0 and accelerated by CUDA, the system provides an estimated 3-second or less delivery timeframe for each image processed by NVIDIA Graphics Processing Unit (GPU). This modular framework permits the extension of additional styles as confirmed through successful styling capture with semantic content maintained.\\

\textbf{Keywords:} Neural Style Transfer, CycleGAN, Generative Adversarial Networks, Deep Learning, Image-to-Image Translation, Computer Vision, Animation Style Transfer, Van Gogh Style

